{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l9EMzpzFbnd"
      },
      "source": [
        "# Kiểm tra mô hình phân loại\n",
        "\n",
        "## 1.Ma trận nhầm lẫn\n",
        "* Tên Tiếng Anh: **confusion matrix**\n",
        "* Kích thước của ma trận: $C \\times C$; với $C$ là số lớp của bài toán phân loại.\n",
        "* **hàng**: nhãn đúng  \n",
        "* **cột**: dự báo của mô hình\n",
        "\n",
        "$\n",
        "M = \\left[\n",
        "\\begin{align}\n",
        "& \\quad \\text{Dự báo: Positive} &\\quad \\text{Dự báo: Nagative} \\\\\n",
        "\\hline\n",
        "\\text{Nhãn: Positive} &\\quad \\mathbb{True Positive} &\\quad \\mathbb{False Negative} \\\\\n",
        "\\text{Nhãn: Negative} &\\quad \\mathbb{False Positive}  &\\quad \\mathbb{True Negative}\n",
        "\\end{align}\n",
        "\\right]\n",
        "$\n",
        "\n",
        "\n",
        "**Tham khảo thêm:**\n",
        "[Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
        "\n",
        "### 1.1 Minh họa\n",
        "\n",
        "* Giả sử có mô hình dự báo đã được huấn luyện để phân loại mỗi mẫu dữ liệu (ví dụ: ảnh) vào một trong hai loại sau:\n",
        "    *  Ác tính (Malignant), còn được là mẫu dương (**Positive**)\n",
        "    *  Lành tính (Benign), mẫu âm (**Negative**)\n",
        "* Khi kiểm tra mô hình nói trên với một tập dữ liệu có $114$ mẫu, với phân bố sau, ta thu được kết quả như trình bày trong ma trận nhầm lẫn $M$, cho bên dưới:\n",
        "    * 47 điểm dữ liệu được gán nhãn **Ác tính** (Positive)\n",
        "    * 67 điểm dữ liệu được gán nhãn **Lành tính** (Negative)\n",
        "    \n",
        "**Ma trận nhầm lẫn**:\n",
        "\n",
        "\n",
        "\n",
        "$\n",
        "M =\n",
        "\\left[\n",
        "\\begin{align}\n",
        "& \\quad \\text{Positive} &\\quad \\text{Nagative} \\\\\n",
        "\\hline\n",
        "\\text{Positive} &\\quad 45 &\\quad 2 \\\\\n",
        "\\text{Negative} &\\quad 4  &\\quad 63\n",
        "\\end{align}\n",
        "\\right]\n",
        "$\n",
        "\n",
        "\n",
        "Thông tin từ ma trận $M$:\n",
        "* Trong số $47$ mẫu ác tính được gán nhãn thì có:\n",
        "    * $45$ mẫu cũng được dự báo là ác tính; kết quả này được gọi là **dương tính thật** hay **True Positive**\n",
        "    * $2$ mẫu bị gán nhầm là lành tính (negative), còn được gọi là **âm tính giả** (**False Negative**)\n",
        "* Trong số $67$ mẫu lành tính được gán nhãn thì có:\n",
        "    * $63$ mẫu cũng được dự báo là lành tính; kết quả này được gọi là **âm tính thật** hay **True Negative**\n",
        "    * $4$ mẫu bị gán nhầm là ác tính (positive), còn được gọi là **dương tính giả** (**False Positive**)\n",
        "\n",
        "### 1.2 Cách xây dựng ma trận nhầm lẫn\n",
        "\n",
        "Ma trận nhầm lẫn được xây dựng từ hai véctơ:\n",
        "*  Véctơ chứa nhãn đúng cho các điểm dữ liệu (**target**)\n",
        "*  Véctơ chứa nhãn dự báo từ mô hình cho các điểm dữ liệu (**prediction**)\n",
        "\n",
        "Với bài toán phân loại có $C$ lớp thì chỉ số các nhãn sẽ thuộc $[0, C)$. Ví dụ, C=3 thì các chỉ số của các nhãn là: $0, 1, 2$. Do đó, **target** và **prediction** chứa các giá trị thuộc $[0, C)$. Hai véctơ **target** và **prediction** phải có chiều dài bằng nhau, và bằng số lượng mẫu dữ liệu được đánh giá.\n",
        "\n",
        "**Ví dụ**:\n",
        "* Số lớp là 3: $C=3$\n",
        "* Kích thước của ma trận nhẫm lẫn: $3 \\times 3$\n",
        "* Giả sử:\n",
        "    *  **target**: $[0, 2, 1, 0]$\n",
        "    *  **prediction**: $[0, 0, 2, 0]$\n",
        "    *  Ta có các cặp (**nhãn**, **dự báo**): $(0, 0), (2, 0), (1, 2), (0, 0)$\n",
        "\n",
        "**Các bước**:\n",
        "* Khởi động:\n",
        "$\n",
        "M =\n",
        "\\left[\n",
        "\\begin{align}\n",
        "0 \\quad 0 \\quad 0\\\\\n",
        "0 \\quad 0 \\quad 0\\\\\n",
        "0 \\quad 0 \\quad 0\n",
        "\\end{align}\n",
        "\\right]\n",
        "$\n",
        "* Xét cặp (**nhãn**, **dự báo**): (0,0) => **dự báo đúng**\n",
        "    * Tăng giá trị $M[0,0] = M[0,0] + 1$; được ma trận\n",
        "$\n",
        "M =\n",
        "\\left[\n",
        "\\begin{align}\n",
        "1 \\quad 0 \\quad 0\\\\\n",
        "0 \\quad 0 \\quad 0\\\\\n",
        "0 \\quad 0 \\quad 0\n",
        "\\end{align}\n",
        "\\right]\n",
        "$\n",
        "* Xét cặp (**nhãn**, **dự báo**): (2,0) => **dự báo sai**: nhãn là $2$ bị nhầm sang $0$\n",
        "    * Tăng giá trị $M[2,0] = M[2,0] + 1$; được ma trận\n",
        "$\n",
        "M =\n",
        "\\left[\n",
        "\\begin{align}\n",
        "1 \\quad 0 \\quad 0\\\\\n",
        "0 \\quad 0 \\quad 0\\\\\n",
        "1 \\quad 0 \\quad 0\n",
        "\\end{align}\n",
        "\\right]\n",
        "$    \n",
        "* Xét cặp (**nhãn**, **dự báo**): (1,2) => **dự báo sai**: nhãn là $1$ bị nhầm sang $2$\n",
        "    * Tăng giá trị $M[1,2] = M[1,2] + 1$; được ma trận\n",
        "$\n",
        "M =\n",
        "\\left[\n",
        "\\begin{align}\n",
        "1 \\quad 0 \\quad 0\\\\\n",
        "0 \\quad 0 \\quad 1\\\\\n",
        "1 \\quad 0 \\quad 0\n",
        "\\end{align}\n",
        "\\right]\n",
        "$    \n",
        "* Xét cặp (**nhãn**, **dự báo**): (0,0) => **dự báo đúng**:\n",
        "    * Tăng giá trị $M[0,0] = M[0,0] + 1$; được ma trận\n",
        "$\n",
        "M =\n",
        "\\left[\n",
        "\\begin{align}\n",
        "2 \\quad 0 \\quad 0\\\\\n",
        "0 \\quad 0 \\quad 1\\\\\n",
        "1 \\quad 0 \\quad 0\n",
        "\\end{align}\n",
        "\\right]\n",
        "$    \n",
        "\n",
        "### 1.3 Lập trình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQTACZuuFbnf",
        "outputId": "e278e12e-6d59-4c4e-efff-290ef8306baf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[90  5  7  4  2]\n",
            " [ 3 79  2  7 10]\n",
            " [ 5  5 82  8  4]\n",
            " [ 5  3  4 85  7]\n",
            " [ 1  1  5  3 73]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#Ma trận nhầm lẫn\n",
        "\n",
        "'''\n",
        "nclasses is None: nclases = giá trị lớn nhất trong target + 1\n",
        "'''\n",
        "def cmatrix(target, prediction, nclasses=None):\n",
        "    if nclasses is None:\n",
        "        C = target.max() + 1\n",
        "    else:\n",
        "        C = nclasses\n",
        "    N = target.shape[0]\n",
        "    M = np.zeros((C, C, N), dtype=np.int64)\n",
        "    M[target.ravel(), prediction.ravel(), np.arange(N)] = 1\n",
        "    return M.sum(axis=2)\n",
        "\n",
        "'''\n",
        "pdiff => (1-pdiff)*100% prediction có nhãn giống target\n",
        "'''\n",
        "def gen_target_prediction(nclasses, nsamples, pdiff=0.2):\n",
        "    #sinh dữ liệu:\n",
        "    C = nclasses; N = nsamples\n",
        "    target = np.random.randint(0, C, (N,))\n",
        "    prediction = target.copy()\n",
        "    change = np.random.randint(0, N, (int(N*pdiff),))\n",
        "    import random\n",
        "    for tidx in change:\n",
        "        labels = list(range(C))\n",
        "        labels.remove(target[tidx])\n",
        "        changeto = random.choice(labels)\n",
        "        prediction[tidx] = changeto\n",
        "    return target, prediction\n",
        "\n",
        "C = 5\n",
        "target, prediction = gen_target_prediction(5, 500, 0.2)\n",
        "M = cmatrix(target, prediction, C)\n",
        "print(M)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUDsFDIHFbnh"
      },
      "source": [
        "## 2. Các độ đo đánh giá:\n",
        "\n",
        "**Ma trận nhầm lẫn**:\n",
        "\n",
        "$\n",
        "M = \\left[\n",
        "\\begin{align}\n",
        "& \\quad \\text{Dự báo: Positive} &\\quad \\text{Dự báo: Nagative} \\\\\n",
        "\\hline\n",
        "\\text{Nhãn: Positive} &\\quad \\mathbb{True Positive} &\\quad \\mathbb{False Negative} \\\\\n",
        "\\text{Nhãn: Negative} &\\quad \\mathbb{False Positive}  &\\quad \\mathbb{True Negative}\n",
        "\\end{align}\n",
        "\\right]\n",
        "$\n",
        "\n",
        "### 2.1 Độ chính xác\n",
        "* Công thức: $precision = \\frac{TruePositive}{TruePositive + FalsePositive}$\n",
        "* Cũng có nghĩa: tổng số mẫu mô hình dự báo **đúng** cho nhãn X chia cho tổng số mẫu mô hình dự báo là nhãn X\n",
        "* Giá **trị nằm trên đường chéo** chia cho **tổng giá trị trên cột** của ma trận nhầm lẫn\n",
        "\n",
        "### 2.2 Độ triệu hồi/độ phủ\n",
        "* Công thức: $recall = \\frac{TruePositive}{TruePositive + FalseNegative}$\n",
        "* Cũng có nghĩa: tổng số mẫu mô hình dự báo **đúng** cho nhãn X chia cho tổng số mẫu được gán (được làm nhãn) là nhãn X\n",
        "* Giá **trị nằm trên đường chéo** chia cho **tổng giá trị trên hàng** của ma trận nhầm lẫn\n",
        "\n",
        "### 2.3 F1-Score\n",
        "* Công thức: $F_1 = 2\\times \\frac{precision \\times recall}{precision + recall} = \\frac{2\\times TruePositive}{2\\times TruePositive + FalseNegative + TrueNegative}$\n",
        "* **Hai lần giá trị nằm trên đường chéo** chia cho **tổng giá trị giá trị trên hàng và trên cột** giao nhau tại giá trị nằm trên đường chéo đang xem xét\n",
        "\n",
        "### 2.4 Accuracy\n",
        "* Công thức: $Accuracy = \\frac{TruePositive + TrueNegative}{TruePositive + TrueNegative + FalsePositive + FalseNegative}$\n",
        "* Cũng có nghĩa: tổng số mẫu mô hình dự báo **đúng** cho tất cả các nhãn chia cho tổng số mẫu có trong tập dữ liệu đánh giá\n",
        "* **Tổng giá trị nằm trên đường chéo** chia cho **tổng giá trị của toàn bộ ma trận nhầm lẫn**\n",
        "\n",
        "### 2.5 Minh họa\n",
        "\n",
        "**Ma trận nhầm lẫn**:\n",
        "\n",
        "$\n",
        "M =\n",
        "\\left[\n",
        "\\begin{align}\n",
        "& \\quad \\text{Positive} &\\quad \\text{Nagative} \\\\\n",
        "\\hline\n",
        "\\text{Positive} &\\quad 45 &\\quad 2 \\\\\n",
        "\\text{Negative} &\\quad 4  &\\quad 63\n",
        "\\end{align}\n",
        "\\right]\n",
        "$\n",
        "\n",
        "**Độ chính xác (precision)**:\n",
        "* Độ chính xác của mô hình với nhãn **Dương** là: $(45/(45 + 4)) \\sim 0.92$\n",
        "* Độ chính xác của mô hình với nhãn **Âm** là: $(63/(63 + 2)) \\sim 0.97$\n",
        "* Độ chính xác trung bình là: $(0.92 + 0.97)/2 \\sim 0.94$\n",
        "* Độ chính xác trung bình **có trọng số** là: $0.92 \\times [47/114] + 0.97 \\times [67/114] \\sim 0.95$\n",
        "\n",
        "**Độ phủ**:\n",
        "* Độ phủ của mô hình với nhãn **Dương** là: $(45/(45 + 2)) \\sim 0.96$\n",
        "* Độ phủ của mô hình với nhãn **Âm** là: $(63/(63 + 4)) \\sim 0.94$\n",
        "* Độ phủ trung bình là: $(0.96 + 0.94)/2 \\sim 0.95$\n",
        "* Độ phủ trung bình **có trọng số** là: $0.96 \\times [47/114] + 0.94 \\times [67/114] \\sim 0.95$\n",
        "\n",
        "**Độ đo F1**\n",
        "* **F1-Measure** của mô hình với nhãn **Dương** là: $2 \\times [0.92 \\times 0.96]/[0.92 + 0.96] \\sim 0.94$\n",
        "* **F1-Measure** của mô hình với nhãn **Âm** là: $2 \\times [0.97 \\times 0.94]/[0.97 + 0.94] \\sim 0.95$\n",
        "* **F1-Measure** trung bình là: $(0.94 + 0.95)/2 \\sim 0.95$\n",
        "* **F1-Measure** trung bình **có trọng số** là: $0.94 \\times [47/114] + 0.95 \\times [67/114] \\sim 0.95$\n",
        "\n",
        "**Độ chính xác (accuracy)**:\n",
        "* Độ chính xác (accuracy) của mô hình là: $(45 + 63)/(45 + 63 + 2 + 4) = 108/114 \\sim 0.95$\n",
        "\n",
        "### 2.6 Lập trình\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYmIsmNWFbnh",
        "outputId": "1968c206-25d2-45b5-9c0e-d707a0084f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision:\n",
            "\t [0.91 0.86 0.92 0.91 0.91]\n",
            "\t 0.900002834347102\n",
            "\t 0.9023323591705387\n",
            "recall:\n",
            "\t [0.9  0.89 0.91 0.91 0.9 ]\n",
            "\t 0.9012647096857623\n",
            "\t 0.9020000000000001\n",
            "f1:\n",
            "\t [0.9  0.87 0.92 0.91 0.9 ]\n",
            "\t 0.9005641330302744\n",
            "\t 0.9021066484163476\n",
            "accuracy:  0.902\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "def precision(target, prediction, nclasses=None):\n",
        "    M = cmatrix(target, prediction, nclasses)\n",
        "    if nclasses is None:\n",
        "        C = target.max() + 1\n",
        "    else:\n",
        "        C = nclasses\n",
        "    weights = M.sum(axis=1)/M.sum()\n",
        "    prec_per_class = M[np.arange(C), np.arange(C)]/M.sum(axis=0)\n",
        "    prec_averaged = prec_per_class.mean()\n",
        "    prec_weighted = (prec_per_class*weights).sum()\n",
        "    return prec_per_class, prec_averaged, prec_weighted\n",
        "\n",
        "def recall(target, prediction, nclasses=None):\n",
        "    M = cmatrix(target, prediction, nclasses)\n",
        "    if nclasses is None:\n",
        "        C = target.max() + 1\n",
        "    else:\n",
        "        C = nclasses\n",
        "\n",
        "    weights = M.sum(axis=1)/M.sum()\n",
        "    rec_per_classes =  M[np.arange(C), np.arange(C)]/M.sum(axis=1)\n",
        "    prec_averaged = rec_per_classes.mean()\n",
        "    prec_weighted = (rec_per_classes*weights).sum()\n",
        "\n",
        "    return rec_per_classes, prec_averaged, prec_weighted\n",
        "\n",
        "def f1_measure(target, prediction, nclasses=None):\n",
        "    prec, _, _ = precision(target, prediction, nclasses)\n",
        "    rec, _, _ = recall(target, prediction, nclasses)\n",
        "    M = cmatrix(target, prediction, nclasses)\n",
        "    if nclasses is None:\n",
        "        C = target.max() + 1\n",
        "    else:\n",
        "        C = nclasses\n",
        "\n",
        "    weights = M.sum(axis=1)/M.sum()\n",
        "    f1_per_classes =  2*prec*rec/(prec+rec)\n",
        "    f1_averaged = f1_per_classes.mean()\n",
        "    f1_weighted = (f1_per_classes*weights).sum()\n",
        "\n",
        "    return f1_per_classes, f1_averaged, f1_weighted\n",
        "\n",
        "def accuracy(target, prediction, nclasses=None):\n",
        "    M = cmatrix(target, prediction, nclasses)\n",
        "    if nclasses is None:\n",
        "        C = target.max() + 1\n",
        "    else:\n",
        "        C = nclasses\n",
        "    return M[np.arange(C), np.arange(C)].sum()/M.sum()\n",
        "\n",
        "C = 5\n",
        "target, prediction = gen_target_prediction(C, 500, 0.1)\n",
        "prec_per_classes, prec_averaged, prec_weighted = precision(target, prediction, C)\n",
        "rec_per_classes, rec_averaged, rec_weighted = recall(target, prediction, C)\n",
        "f1_per_classes, f1_averaged, f1_weighted = f1_measure(target, prediction, C)\n",
        "acc = accuracy(target, prediction, C)\n",
        "\n",
        "print('precision:')\n",
        "print('\\t', prec_per_classes)\n",
        "print('\\t', prec_averaged)\n",
        "print('\\t', prec_weighted)\n",
        "\n",
        "print('recall:')\n",
        "print('\\t', rec_per_classes)\n",
        "print('\\t', rec_averaged)\n",
        "print('\\t', rec_weighted)\n",
        "\n",
        "print('f1:')\n",
        "print('\\t', f1_per_classes)\n",
        "print('\\t', f1_averaged)\n",
        "print('\\t', f1_weighted)\n",
        "\n",
        "print('accuracy: ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17duFy75Fbnh"
      },
      "source": [
        "\n",
        "## 3. Ứng dụng trong bài toán phân loại\n",
        "\n",
        "**Tham khảo**\n",
        "* Nên sử dụng thư viện **scikit-learn**: [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_taA7rbFbnh",
        "outputId": "dc495381-cd99-46b6-ebc1-159566a05e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REPORT FROM SKLEARN: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       0.90      0.98      0.94        47\n",
            "      benign       0.98      0.93      0.95        67\n",
            "\n",
            "    accuracy                           0.95       114\n",
            "   macro avg       0.94      0.95      0.95       114\n",
            "weighted avg       0.95      0.95      0.95       114\n",
            "\n",
            "####################################################################################################\n",
            "YOUR REPORT: \n",
            "precision:\n",
            "\tprec_per_classes: [0.9  0.98]\n",
            "\tprec_averaged:   0.94\n",
            "\tprec_weighted:   0.95\n",
            "recall:\n",
            "\trec_per_classes: [0.98 0.93]\n",
            "\trec_averaged:   0.95\n",
            "\trec_weighted:   0.95\n",
            "f1:\n",
            "\tf1_per_classes: [0.94 0.95]\n",
            "\tf1_averaged:   0.95\n",
            "\tf1_weighted:   0.95\n",
            "accuracy:    0.95\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#Nạp dữ liệu + chia tách\n",
        "dataset = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset.data, dataset.target, test_size=0.2, random_state=0)\n",
        "\n",
        "#Học máy\n",
        "model = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#from sklearn\n",
        "print('REPORT FROM SKLEARN: ')\n",
        "print(classification_report(y_test, y_pred, target_names=dataset.target_names))\n",
        "\n",
        "#your API\n",
        "print('#'*100)\n",
        "print('YOUR REPORT: ')\n",
        "C = len(dataset.target_names)\n",
        "prec_per_classes, prec_averaged, prec_weighted = precision(y_test, y_pred, C)\n",
        "rec_per_classes, rec_averaged, rec_weighted = recall(y_test, y_pred, C)\n",
        "f1_per_classes, f1_averaged, f1_weighted = f1_measure(y_test, y_pred, C)\n",
        "acc = accuracy(y_test, y_pred, C)\n",
        "\n",
        "print('precision:')\n",
        "print('\\tprec_per_classes:', prec_per_classes)\n",
        "print('\\tprec_averaged:{:7.2f}'.format(prec_averaged))\n",
        "print('\\tprec_weighted:{:7.2f}'.format(prec_weighted))\n",
        "\n",
        "print('recall:')\n",
        "print('\\trec_per_classes:', rec_per_classes)\n",
        "print('\\trec_averaged:{:7.2f}'.format(rec_averaged))\n",
        "print('\\trec_weighted:{:7.2f}'.format(rec_weighted))\n",
        "\n",
        "print('f1:')\n",
        "print('\\tf1_per_classes:', f1_per_classes)\n",
        "print('\\tf1_averaged:{:7.2f}'.format(f1_averaged))\n",
        "print('\\tf1_weighted:{:7.2f}'.format(f1_weighted))\n",
        "\n",
        "print('accuracy: {:7.2f}'.format(acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqWt5S9GFbni"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
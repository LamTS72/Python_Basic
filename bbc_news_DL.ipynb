{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fb3d82e4-5188-48f8-be9a-a09e179a8f64",
      "metadata": {
        "id": "fb3d82e4-5188-48f8-be9a-a09e179a8f64"
      },
      "source": [
        "# References\n",
        "* [Bert for text classification](https://www.kaggle.com/code/joydeb28/text-classification-with-bert-pytorch)\n",
        "* [BBC-News](http://mlg.ucd.ie/datasets/bbc.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46dac604-14fa-4bb8-ad58-71015297f653",
      "metadata": {
        "id": "46dac604-14fa-4bb8-ad58-71015297f653",
        "outputId": "34e88b1d-df4b-4bc0-e189-eeef49229b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import json\n",
        "import os\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")\n",
        "print(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32238f69-8b86-4098-aa67-76a9eb0010b8",
      "metadata": {
        "id": "32238f69-8b86-4098-aa67-76a9eb0010b8"
      },
      "source": [
        "# 1- Preparing data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb3edc2e-517c-4ede-956b-683d8b574d81",
      "metadata": {
        "id": "cb3edc2e-517c-4ede-956b-683d8b574d81"
      },
      "source": [
        "## 1.1- Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b3d5c6-1cf1-4032-aadf-044d67693c81",
      "metadata": {
        "id": "d5b3d5c6-1cf1-4032-aadf-044d67693c81",
        "outputId": "5316d505-e5ce-4e22-d25b-ca525bff5568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-27 09:32:29--  http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip\n",
            "Resolving mlg.ucd.ie (mlg.ucd.ie)... 137.43.93.132\n",
            "Connecting to mlg.ucd.ie (mlg.ucd.ie)|137.43.93.132|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2874079 (2.7M) [application/zip]\n",
            "Saving to: ‘bbc-fulltext.zip’\n",
            "\n",
            "bbc-fulltext.zip    100%[===================>]   2.74M  1.20MB/s    in 2.3s    \n",
            "\n",
            "2024-03-27 09:32:32 (1.20 MB/s) - ‘bbc-fulltext.zip’ saved [2874079/2874079]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!rm -f bbc-fulltext.zip\n",
        "!wget http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip\n",
        "!rm -rf bbc\n",
        "!unzip -q bbc-fulltext.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb3c9f5-e166-44ce-8322-e94d55a0c7a8",
      "metadata": {
        "id": "0cb3c9f5-e166-44ce-8322-e94d55a0c7a8"
      },
      "source": [
        "## 1.2- Building list of class names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2697275f-5ed2-42f7-86c6-9f44cff43235",
      "metadata": {
        "id": "2697275f-5ed2-42f7-86c6-9f44cff43235"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "path = \"./bbc\"\n",
        "class_names = os.listdir(path)\n",
        "class_names = [p for p in class_names if os.path.isdir(os.path.join(path, p))]\n",
        "class_names\n",
        "lb_encoder = LabelEncoder().fit(class_names)\n",
        "class_idx = lb_encoder.transform(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d364c105-898a-4a54-8d22-62887854bb42",
      "metadata": {
        "id": "d364c105-898a-4a54-8d22-62887854bb42",
        "outputId": "b7585f70-2296-422b-b726-bf77a99cb80a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2225\n",
            "2225\n"
          ]
        }
      ],
      "source": [
        "all_files = []\n",
        "labels = []\n",
        "for label in class_names:\n",
        "  files = os.listdir(os.path.join(path, label))\n",
        "  files = [os.path.join(path, label, p) for p in files if p.endswith('.txt')]\n",
        "  all_files = all_files + files\n",
        "  labels = labels + [label]*len(files)\n",
        "\n",
        "text = []\n",
        "for file in all_files:\n",
        "  with open(file) as f:\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "  text.append(\" \".join(lines))\n",
        "\n",
        "print(len(text))\n",
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11d2b532-c283-4190-b3d0-ab0994d240c8",
      "metadata": {
        "id": "11d2b532-c283-4190-b3d0-ab0994d240c8",
        "outputId": "689104d2-38a6-47fd-bca9-a909b7df6d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2225 entries, 0 to 2224\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    2225 non-null   object\n",
            " 1   labels  2225 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 34.9+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_table = pd.DataFrame({\n",
        "    \"text\": text,\n",
        "    \"labels\": labels\n",
        "})\n",
        "data_table.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6639b92b-b055-4119-84f9-069f1120d04f",
      "metadata": {
        "id": "6639b92b-b055-4119-84f9-069f1120d04f",
        "outputId": "d1db0f17-54d8-434e-c9c3-caa6ef016572"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "labels\n",
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_table.labels.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5acc3b38-01e8-43cf-b6d0-590e26f9b5e7",
      "metadata": {
        "id": "5acc3b38-01e8-43cf-b6d0-590e26f9b5e7",
        "outputId": "f81e180f-15ce-4377-8b9f-3afbf69ca0a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='labels'>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_table.labels.value_counts().plot(kind=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d13083-7852-47ce-a68b-0eb304eb6ccc",
      "metadata": {
        "id": "c2d13083-7852-47ce-a68b-0eb304eb6ccc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_table, test_table = train_test_split(data_table, test_size=0.2, random_state=2023)\n",
        "train_table, valid_table = train_test_split(train_table, test_size=0.2, random_state=2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df167895-e1cf-495e-99e2-3574d3db1fb9",
      "metadata": {
        "id": "df167895-e1cf-495e-99e2-3574d3db1fb9",
        "outputId": "c8f577df-4895-49a0-b2f6-77321318b8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1424 entries, 1971 to 16\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1424 non-null   object\n",
            " 1   labels  1424 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 33.4+ KB\n"
          ]
        }
      ],
      "source": [
        "train_table.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5c721f-0f7b-45f5-bffa-73e5202702d1",
      "metadata": {
        "id": "6b5c721f-0f7b-45f5-bffa-73e5202702d1",
        "outputId": "de48a8f5-333b-4c30-b3b2-57b9f31e4b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 356 entries, 1084 to 695\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    356 non-null    object\n",
            " 1   labels  356 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 8.3+ KB\n"
          ]
        }
      ],
      "source": [
        "valid_table.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2835d80-5d6f-4be0-9190-7a8c8d7d86fd",
      "metadata": {
        "id": "e2835d80-5d6f-4be0-9190-7a8c8d7d86fd",
        "outputId": "e9389ece-1c62-4c6b-ff55-621773839d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 445 entries, 294 to 1139\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    445 non-null    object\n",
            " 1   labels  445 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 10.4+ KB\n"
          ]
        }
      ],
      "source": [
        "test_table.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deb1370d-8572-4c70-aae8-f6e307a33afa",
      "metadata": {
        "id": "deb1370d-8572-4c70-aae8-f6e307a33afa",
        "outputId": "224daf5b-4088-4fb8-bdfa-d1ad2c3cc034"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Show over for MTV\\'s The Osbournes\\n \\n Rock star Ozzy Osbourne has said his family will not make any more episodes of reality TV show The Osbournes.\\n \\n \"At the end of it I didn\\'t like having cameras around the house all the time,\" the Black Sabbath singer told reporters at the MTV Europe Awards in Rome. His wife Sharon, who also appears in the popular MTV show based on the Osbournes\\' family life, agreed. \"Now everybody\\'s doing reality shows. He\\'s done it, he\\'s been there, he\\'s got to do something else,\" she said.\\n \\n Ozzy Osbourne said he had had enough of the work involved in making the series. \"When you watch a 25-minute episode, I\\'ve been filming all day,\" he said. Sharon Osbourne is currently appearing as a judge and mentor in ITV1 talent show The X-Factor alongside Simon Cowell and Louis Walsh.\\n \\n Earlier this year she topped a poll of the most important people in rock, for her part in guiding the career of husband Ozzy and her family. She was the driving force behind The Osbournes, which ran for three series, earning the family a reported $85m (£46m). The renewed popularity for Ozzy has seen sales of his merchandise hit the $50m (£27.2m) mark, a record for a heavy metal artist. Sales of T-shirts, accessories and action figures have rocketed since The Osbournes hit screens. At its peak, The Osbournes had a regular audience of eight million, with America\\'s TV Guide magazine describing the series as \"a cross between The Simpsons and This Is Spinal Tap\". Osbourne himself was at a loss to explain its popularity: \"I suppose Americans get a kick out of watching a crazy Brit family like us make complete fools of ourselves every week.\"\\n'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_table.iloc[10][\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9f45d7-9426-4a47-818e-2480e9083690",
      "metadata": {
        "id": "2a9f45d7-9426-4a47-818e-2480e9083690"
      },
      "outputs": [],
      "source": [
        "train_text, valid_text, test_text = [table[\"text\"].tolist() for table in [train_table, valid_table, test_table]]\n",
        "train_labelidx, valid_labelidx, test_labelidx = [lb_encoder.transform(table[\"labels\"]).tolist() for table in [train_table, valid_table, test_table]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "740976cc-3761-4e24-92e8-2cd0f58c382c",
      "metadata": {
        "id": "740976cc-3761-4e24-92e8-2cd0f58c382c"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d59232-8c03-4258-81e2-1026d5a945b3",
      "metadata": {
        "id": "34d59232-8c03-4258-81e2-1026d5a945b3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "class Tokenizer(object):\n",
        "    def __init__(self, pretrained_name=\"bert-base-uncased\", max_seq_len=512):\n",
        "        self.pretrained_name = pretrained_name\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_name)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        tokens = self.tokenizer.batch_encode_plus(\n",
        "            text,\n",
        "            max_length = self.max_seq_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation=True,\n",
        "            return_token_type_ids=False\n",
        "        )\n",
        "        return tokens\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "train_tokens, valid_tokens, test_tokens = [tokenizer.tokenize(text) for text in [train_text, valid_text, test_text]]\n",
        "train_seq, train_mask, train_y = [torch.tensor(data) for data in [train_tokens['input_ids'], train_tokens['attention_mask'], train_labelidx]]\n",
        "valid_seq, valid_mask, valid_y = [torch.tensor(data) for data in [valid_tokens['input_ids'], valid_tokens['attention_mask'], valid_labelidx]]\n",
        "test_seq, test_mask, test_y = [torch.tensor(data) for data in [test_tokens['input_ids'], test_tokens['attention_mask'], test_labelidx]]\n",
        "\n",
        "train_tensor = TensorDataset(train_seq, train_mask, train_y)\n",
        "valid_tensor = TensorDataset(valid_seq, valid_mask, valid_y)\n",
        "test_tensor = TensorDataset(test_seq, test_mask, test_y)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = DataLoader(train_tensor, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_tensor, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_tensor, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7525de6e-6054-49e3-95f7-a9b53d289c7d",
      "metadata": {
        "id": "7525de6e-6054-49e3-95f7-a9b53d289c7d",
        "outputId": "c27070ab-e5c5-46af-e15e-865b60a758f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512]) torch.Size([16, 512]) torch.Size([16]) [3, 4, 3, 2, 0, 3, 0, 1, 2, 1, 1, 3, 3, 3, 0, 4]\n",
            "torch.Size([16, 512]) torch.Size([16, 512]) torch.Size([16]) [0, 4, 1, 2, 3, 3, 3, 4, 0, 2, 3, 4, 0, 4, 3, 3]\n",
            "torch.Size([16, 512]) torch.Size([16, 512]) torch.Size([16]) [2, 1, 2, 1, 3, 0, 1, 1, 2, 0, 2, 1, 1, 1, 3, 2]\n",
            "torch.Size([16, 512]) torch.Size([16, 512]) torch.Size([16]) [2, 4, 0, 0, 4, 3, 3, 2, 2, 3, 3, 4, 1, 4, 3, 3]\n",
            "torch.Size([16, 512]) torch.Size([16, 512]) torch.Size([16]) [3, 1, 2, 2, 1, 4, 4, 1, 2, 1, 3, 3, 0, 0, 4, 3]\n",
            "torch.Size([16, 512]) torch.Size([16, 512]) torch.Size([16]) [1, 0, 4, 1, 1, 0, 0, 4, 2, 3, 0, 0, 1, 0, 3, 3]\n",
            "torch.Size([16, 512]) torch.Size([16, 512]) torch.Size([16]) [2, 4, 1, 4, 0, 2, 1, 0, 3, 2, 3, 1, 4, 3, 4, 3]\n"
          ]
        }
      ],
      "source": [
        "for idx, (seq, mask, y) in enumerate(train_loader):\n",
        "    print(seq.shape, mask.shape, y.shape, y.tolist())\n",
        "    if idx > 5:\n",
        "        break\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d7c839-53eb-461e-bbf0-522c2036952f",
      "metadata": {
        "id": "50d7c839-53eb-461e-bbf0-522c2036952f"
      },
      "source": [
        "# 2- Defining Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "466d2428-5b74-4023-8d2b-6f0b6bd710ee",
      "metadata": {
        "id": "466d2428-5b74-4023-8d2b-6f0b6bd710ee"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import utils\n",
        "\n",
        "class NewsClassifier(utils.BaseModel):\n",
        "    def __init__(self, nclasses, pretrained_name=\"bert-base-uncased\"):\n",
        "        super().__init__()\n",
        "\n",
        "        self.nclasses = nclasses\n",
        "        self.pretrained_name = pretrained_name\n",
        "        self.feature_extractor = BertModel.from_pretrained(pretrained_name)\n",
        "        for param in self.feature_extractor.parameters(): # dot not learn\n",
        "            param.requires_grad = False\n",
        "        #\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc1 = nn.Linear(768,512)\n",
        "        self.fc2 = nn.Linear(512,self.nclasses)\n",
        "\n",
        "    def forward(self, token_ids, mask):\n",
        "        feature = self.feature_extractor(token_ids, attention_mask=mask)\n",
        "        cls_feature = feature.last_hidden_state[:, 0, :]\n",
        "        x = self.dropout(F.relu(self.fc1(cls_feature)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def from_pretrained(nclasses, path_to_model):\n",
        "        checkpoint = torch.load(path_to_model)\n",
        "        if 'loss_meter.weight' in list(checkpoint['model'].keys()):\n",
        "            del checkpoint['model']['loss_meter.weight']\n",
        "        pretrained_model = NewsClassifier(nclasses)\n",
        "        pretrained_model.load_state_dict(checkpoint['model'])\n",
        "        return pretrained_model\n",
        "\n",
        "class Predictor(NewsClassifier):\n",
        "    def __init__(self, idx2name, nclasses=5, pretrained_name=\"bert-base-uncased\"):\n",
        "        super().__init__(nclasses, pretrained_name)\n",
        "        self.idx2name = idx2name\n",
        "\n",
        "    def from_pretrained(self, path_to_model):\n",
        "        checkpoint = torch.load(path_to_model)\n",
        "        if 'loss_meter.weight' in list(checkpoint['model'].keys()):\n",
        "            del checkpoint['model']['loss_meter.weight']\n",
        "        self.load_state_dict(checkpoint['model'])\n",
        "        return self\n",
        "\n",
        "    def predict(self, text):\n",
        "        \"\"\"\n",
        "        text: text | list of texts\n",
        "        \"\"\"\n",
        "        if isinstance(text, str):\n",
        "            text = [text]\n",
        "        elif not isinstance(text, list):\n",
        "            raise Exception(f\"type of text = {type(text)}: not supported.\")\n",
        "        else:\n",
        "            pass\n",
        "        #\n",
        "        tokenizer = Tokenizer()\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        seqs, masks = [torch.tensor(data) for data in [tokens['input_ids'], tokens['attention_mask']]]\n",
        "        preds = super().forward(seqs, masks)\n",
        "        preds = F.softmax(preds)\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        preds = np.argmax(preds, axis=-1).tolist()\n",
        "        names = [self.idx2name[idx] for idx in preds]\n",
        "        return names\n",
        "\n",
        "####\n",
        "model = NewsClassifier(len(class_names))\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c35bd73-e4e6-4c1f-ab0b-b444346b4449",
      "metadata": {
        "id": "5c35bd73-e4e6-4c1f-ab0b-b444346b4449",
        "outputId": "263bd3dc-df06-4dcc-85bd-f08ca5c00853"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  1/40 | Batch: 89/89:   2%|▎         | 89/3560 [00:12<07:37,  7.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0263         0.8617         0.8578         0.8582         0.8575\n",
            "Validation summary                0.0105         0.9438         0.9417         0.9494         0.9421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  2/40 | Batch: 89/89:   5%|▌         | 178/3560 [00:27<07:27,  7.56it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0076         0.9635         0.9622         0.9629         0.9625\n",
            "Validation summary                0.0093         0.9579         0.9540         0.9600         0.9557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  3/40 | Batch: 89/89:   8%|▊         | 267/3560 [00:42<07:18,  7.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0061         0.9656         0.9641         0.9660         0.9650\n",
            "Validation summary                0.0067         0.9691         0.9663         0.9710         0.9682\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  4/40 | Batch: 89/89:  10%|█         | 356/3560 [00:56<07:07,  7.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0046         0.9747         0.9744         0.9743         0.9744\n",
            "Validation summary                0.0059         0.9747         0.9720         0.9770         0.9742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  5/40 | Batch: 89/89:  12%|█▎        | 445/3560 [01:11<06:56,  7.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0036         0.9754         0.9748         0.9764         0.9754\n",
            "Validation summary                0.0111         0.9551         0.9526         0.9576         0.9535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  6/40 | Batch: 89/89:  15%|█▌        | 534/3560 [01:26<06:45,  7.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0054         0.9698         0.9689         0.9704         0.9696\n",
            "Validation summary                0.0088         0.9635         0.9627         0.9639         0.9623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  7/40 | Batch: 89/89:  18%|█▊        | 623/3560 [01:40<06:33,  7.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0042         0.9754         0.9754         0.9755         0.9754\n",
            "Validation summary                0.0163         0.9326         0.9465         0.9325         0.9360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  8/40 | Batch: 89/89:  20%|██        | 712/3560 [01:56<06:20,  7.48it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0033         0.9810         0.9805         0.9807         0.9806\n",
            "Validation summary                0.0067         0.9635         0.9651         0.9649         0.9649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  9/40 | Batch: 89/89:  22%|██▎       | 801/3560 [02:11<06:09,  7.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0027         0.9853         0.9840         0.9849         0.9844\n",
            "Validation summary                0.0083         0.9747         0.9722         0.9750         0.9731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 10/40 | Batch: 89/89:  25%|██▌       | 890/3560 [02:26<05:59,  7.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0039         0.9789         0.9781         0.9792         0.9786\n",
            "Validation summary                0.0141         0.9522         0.9501         0.9550         0.9511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 11/40 | Batch: 89/89:  28%|██▊       | 979/3560 [02:40<05:48,  7.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0033         0.9789         0.9786         0.9783         0.9784\n",
            "Validation summary                0.0120         0.9579         0.9577         0.9599         0.9573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 12/40 | Batch: 89/89:  30%|███       | 1068/3560 [02:55<05:36,  7.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0022         0.9881         0.9873         0.9881         0.9877\n",
            "Validation summary                0.0143         0.9494         0.9626         0.9494         0.9534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 13/40 | Batch: 89/89:  32%|███▎      | 1157/3560 [03:10<05:23,  7.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0016         0.9881         0.9872         0.9883         0.9877\n",
            "Validation summary                0.0106         0.9691         0.9702         0.9695         0.9693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 14/40 | Batch: 89/89:  35%|███▌      | 1246/3560 [03:25<05:12,  7.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0025         0.9874         0.9872         0.9877         0.9875\n",
            "Validation summary                0.0179         0.9410         0.9463         0.9429         0.9415\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 15/40 | Batch: 89/89:  38%|███▊      | 1335/3560 [03:40<05:01,  7.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0019         0.9909         0.9906         0.9906         0.9906\n",
            "Validation summary                0.0118         0.9607         0.9631         0.9643         0.9626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 16/40 | Batch: 89/89:  40%|████      | 1424/3560 [03:55<04:48,  7.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0014         0.9930         0.9931         0.9933         0.9932\n",
            "Validation summary                0.0067         0.9747         0.9766         0.9744         0.9753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 17/40 | Batch: 89/89:  42%|████▎     | 1513/3560 [04:10<04:37,  7.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0010         0.9958         0.9954         0.9961         0.9957\n",
            "Validation summary                0.0125         0.9635         0.9665         0.9667         0.9655\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 18/40 | Batch: 89/89:  45%|████▌     | 1602/3560 [04:25<04:25,  7.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0021         0.9881         0.9881         0.9881         0.9881\n",
            "Validation summary                0.0103         0.9663         0.9684         0.9691         0.9679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 19/40 | Batch: 89/89:  48%|████▊     | 1691/3560 [04:40<04:13,  7.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0019         0.9895         0.9889         0.9897         0.9893\n",
            "Validation summary                0.0223         0.9382         0.9521         0.9408         0.9430\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 20/40 | Batch: 89/89:  50%|█████     | 1780/3560 [04:55<04:01,  7.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0012         0.9916         0.9911         0.9910         0.9910\n",
            "Validation summary                0.0119         0.9775         0.9754         0.9783         0.9766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 21/40 | Batch: 89/89:  52%|█████▎    | 1869/3560 [05:10<03:49,  7.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0020         0.9888         0.9882         0.9886         0.9884\n",
            "Validation summary                0.0176         0.9522         0.9517         0.9549         0.9512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 22/40 | Batch: 89/89:  55%|█████▌    | 1958/3560 [05:25<03:38,  7.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0024         0.9895         0.9887         0.9887         0.9887\n",
            "Validation summary                0.0074         0.9831         0.9803         0.9843         0.9820\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 23/40 | Batch: 89/89:  57%|█████▊    | 2047/3560 [05:40<03:26,  7.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0014         0.9888         0.9885         0.9887         0.9886\n",
            "Validation summary                0.0148         0.9691         0.9680         0.9708         0.9688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 24/40 | Batch: 89/89:  60%|██████    | 2136/3560 [05:55<03:13,  7.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0019         0.9895         0.9887         0.9899         0.9893\n",
            "Validation summary                0.0128         0.9691         0.9680         0.9699         0.9683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 25/40 | Batch: 89/89:  62%|██████▎   | 2225/3560 [06:10<03:02,  7.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0015         0.9923         0.9922         0.9922         0.9922\n",
            "Validation summary                0.0113         0.9635         0.9674         0.9621         0.9640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 26/40 | Batch: 89/89:  65%|██████▌   | 2314/3560 [06:25<02:50,  7.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0016         0.9916         0.9915         0.9913         0.9914\n",
            "Validation summary                0.0132         0.9635         0.9624         0.9658         0.9633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 27/40 | Batch: 89/89:  68%|██████▊   | 2403/3560 [06:40<02:38,  7.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0018         0.9909         0.9904         0.9908         0.9906\n",
            "Validation summary                0.0089         0.9747         0.9722         0.9741         0.9724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 28/40 | Batch: 89/89:  70%|███████   | 2492/3560 [06:55<02:26,  7.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0021         0.9902         0.9898         0.9903         0.9901\n",
            "Validation summary                0.0110         0.9747         0.9724         0.9749         0.9732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 29/40 | Batch: 89/89:  72%|███████▎  | 2581/3560 [07:10<02:14,  7.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0011         0.9930         0.9927         0.9924         0.9926\n",
            "Validation summary                0.0109         0.9719         0.9691         0.9725         0.9702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 30/40 | Batch: 89/89:  75%|███████▌  | 2670/3560 [07:25<02:02,  7.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0018         0.9909         0.9903         0.9909         0.9906\n",
            "Validation summary                0.0260         0.9382         0.9432         0.9414         0.9389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 31/40 | Batch: 89/89:  78%|███████▊  | 2759/3560 [07:40<01:50,  7.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0013         0.9930         0.9931         0.9931         0.9931\n",
            "Validation summary                0.0113         0.9691         0.9682         0.9696         0.9685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 32/40 | Batch: 89/89:  80%|████████  | 2848/3560 [07:55<01:37,  7.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0018         0.9923         0.9922         0.9923         0.9922\n",
            "Validation summary                0.0108         0.9719         0.9721         0.9730         0.9722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 33/40 | Batch: 89/89:  82%|████████▎ | 2937/3560 [08:10<01:25,  7.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0005         0.9972         0.9972         0.9974         0.9973\n",
            "Validation summary                0.0158         0.9579         0.9593         0.9596         0.9585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 34/40 | Batch: 89/89:  85%|████████▌ | 3026/3560 [08:26<01:13,  7.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0005         0.9965         0.9965         0.9966         0.9965\n",
            "Validation summary                0.0107         0.9831         0.9848         0.9842         0.9844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 35/40 | Batch: 89/89:  88%|████████▊ | 3115/3560 [08:41<01:01,  7.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0027         0.9888         0.9884         0.9891         0.9887\n",
            "Validation summary                0.0313         0.9326         0.9410         0.9383         0.9353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 36/40 | Batch: 89/89:  90%|█████████ | 3204/3560 [08:56<00:48,  7.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0012         0.9944         0.9941         0.9943         0.9942\n",
            "Validation summary                0.0164         0.9635         0.9613         0.9649         0.9618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 37/40 | Batch: 89/89:  92%|█████████▎| 3293/3560 [09:11<00:36,  7.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0031         0.9853         0.9843         0.9850         0.9846\n",
            "Validation summary                0.0132         0.9719         0.9710         0.9721         0.9712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 38/40 | Batch: 89/89:  95%|█████████▌| 3382/3560 [09:26<00:24,  7.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0011         0.9951         0.9950         0.9948         0.9949\n",
            "Validation summary                0.0130         0.9775         0.9748         0.9783         0.9761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 39/40 | Batch: 89/89:  98%|█████████▊| 3471/3560 [09:42<00:12,  7.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0004         0.9965         0.9962         0.9966         0.9964\n",
            "Validation summary                0.0214         0.9438         0.9473         0.9483         0.9454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 40/40 | Batch: 89/89: 100%|██████████| 3560/3560 [09:57<00:00,  7.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        Loss(per-sample)       accuracy      precision         recall       f1_score\n",
            "Training summary                  0.0009         0.9937         0.9936         0.9938         0.9937\n",
            "Validation summary                0.0074         0.9831         0.9834         0.9830         0.9831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 40/40 | Batch: 89/89: 100%|██████████| 3560/3560 [10:00<00:00,  5.93it/s]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_wts = compute_class_weight('balanced', classes=np.unique(train_y.numpy()), y=train_y.numpy())\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)\n",
        "loss_meter = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "nepoches = 40\n",
        "\n",
        "model.compile(optimizer, loss_meter,\n",
        "              metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"],\n",
        "              save_best_to=\"the_best.pt\",\n",
        "              save_last_to=\"last_model.pt\")\n",
        "model.fit(train_loader, valid_loader, nepoches = nepoches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df7aecef-ae24-400e-8303-88066d6bf9f0",
      "metadata": {
        "id": "df7aecef-ae24-400e-8303-88066d6bf9f0",
        "outputId": "abc77bfd-8124-4070-88bd-26bd7cbc5016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Evaluation: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97        92\n",
            "           1       0.99      0.99      0.99        84\n",
            "           2       0.99      0.97      0.98        88\n",
            "           3       1.00      1.00      1.00        94\n",
            "           4       0.99      0.99      0.99        87\n",
            "\n",
            "    accuracy                           0.98       445\n",
            "   macro avg       0.98      0.98      0.98       445\n",
            "weighted avg       0.98      0.98      0.98       445\n",
            "\n",
            "====================================================================================================\n",
            "Loss(per-sample):         0.0065\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "rs =model.evaluate(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c91176d2-76f6-4a50-a1d5-b260478c18ea",
      "metadata": {
        "id": "c91176d2-76f6-4a50-a1d5-b260478c18ea",
        "outputId": "b003a916-ded5-4aa6-de99-38dd35740645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Evaluation: \n",
            "----------------------------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.99      0.91        92\n",
            "           1       0.98      0.99      0.98        84\n",
            "           2       1.00      0.90      0.95        88\n",
            "           3       1.00      0.97      0.98        94\n",
            "           4       0.99      0.93      0.96        87\n",
            "\n",
            "    accuracy                           0.96       445\n",
            "   macro avg       0.96      0.95      0.96       445\n",
            "weighted avg       0.96      0.96      0.96       445\n",
            "\n",
            "====================================================================================================\n",
            "Loss(per-sample):         0.0097\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "#pretrained_model = NewsClassifier.from_pretrained(5, \"last_model.pt\")\n",
        "pretrained_model = NewsClassifier.from_pretrained(5, \"the_best.pt\")\n",
        "pretrained_model.compile(optimizer, loss_meter,\n",
        "              metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"],\n",
        "              save_best_to=\"the_best.pt\",\n",
        "              save_last_to=\"last_model.pt\")\n",
        "pretrained_model.to(device)\n",
        "rs = pretrained_model.evaluate(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8054c970-f16a-40e1-858a-5c4d2b62897b",
      "metadata": {
        "id": "8054c970-f16a-40e1-858a-5c4d2b62897b",
        "outputId": "77e34713-0001-4368-9ac0-aa842b4842f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['entertainment', 'business', 'entertainment', 'sport']\n"
          ]
        }
      ],
      "source": [
        "idx2name = dict(zip(class_idx, class_names))\n",
        "predictor = Predictor(idx2name)\n",
        "predictor.from_pretrained(\"last_model.pt\")\n",
        "preds = predictor.predict(test_text[:4])\n",
        "print(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b21a104-58ae-4bd7-a2c9-7e9e7161cc30",
      "metadata": {
        "id": "1b21a104-58ae-4bd7-a2c9-7e9e7161cc30",
        "outputId": "95383535-028a-42f0-c831-2e574422917b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['business']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text1 = \"\"\"\n",
        "For a while, that approach seemed to work. As the boy-wonder of crypto, Bankman-Fried got rich faster than almost anyone in history, amassing an estimated $26bn in personal wealth, countless magazine covers and sweeping political influence. The flameout was even faster.\n",
        "\n",
        "The tweet was, as discussed, net bad. Billions gushed out of the platform in less than five days. When it was all over, more than $8bn in customer funds were missing and the company was bankrupt. Five weeks after that, prosecutors in Manhattan charged Bankman-Fried, who had already resigned, with several financial offences including wire fraud, securities fraud, commodities fraud and money laundering.\n",
        "\n",
        "Over four weeks of trial, two contradictory stories emerged. In one, the former mogul was a brilliant but hapless savant, whose mistakes as CEO allowed for massive fraud to be carried out under his nose. In the other, supported by former members of his inner circle, Bankman-Fried syphoned billions of dollars of customer money, banking on the odds he'd never be caught.\n",
        "\n",
        "Both tellings reveal how tightly the fortunes of FTX were tied to the image of its founder, whose oddball magnetism drew former presidents, celebrities, and corporate titans into his orbit and his multi-billion dollar gamble.\n",
        "\"\"\"\n",
        "predictor.predict(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f260285f-0508-4554-9e56-b1ef51fe95b1",
      "metadata": {
        "id": "f260285f-0508-4554-9e56-b1ef51fe95b1",
        "outputId": "1e08dc12-c7ea-4deb-8e19-46891b74eb33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['business']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text1 = \"\"\"\n",
        "For a while, that approach seemed to work. As the boy-wonder of crypto, Bankman-Fried got rich faster than almost anyone in history, amassing an estimated $26bn in personal wealth, countless magazine covers and sweeping political influence. The flameout was even faster.\n",
        "\n",
        "The tweet was, as discussed, net bad. Billions gushed out of the platform in less than five days. When it was all over, more than $8bn in customer funds were missing and the company was bankrupt. Five weeks after that, prosecutors in Manhattan charged Bankman-Fried, who had already resigned, with several financial offences including wire fraud, securities fraud, commodities fraud and money laundering.\n",
        "\n",
        "Over four weeks of trial, two contradictory stories emerged. In one, the former mogul was a brilliant but hapless savant, whose mistakes as CEO allowed for massive fraud to be carried out under his nose. In the other, supported by former members of his inner circle, Bankman-Fried syphoned billions of dollars of customer money, banking on the odds he'd never be caught.\n",
        "\n",
        "Both tellings reveal how tightly the fortunes of FTX were tied to the image of its founder, whose oddball magnetism drew former presidents, celebrities, and corporate titans into his orbit and his multi-billion dollar gamble.\n",
        "\"\"\"\n",
        "predictor.predict(text1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03a7f65-ca37-48e0-b10a-2f3895f20401",
      "metadata": {
        "id": "e03a7f65-ca37-48e0-b10a-2f3895f20401"
      },
      "source": [
        "[url2text](https://stackoverflow.com/questions/45768441/hangs-on-open-url-with-urllib-python3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78325f60-20c3-4989-9292-5340b5b8afc2",
      "metadata": {
        "id": "78325f60-20c3-4989-9292-5340b5b8afc2",
        "outputId": "27c29725-10aa-46ac-8eee-830ccf439308"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['entertainment', 'sport', 'politics', 'business', 'tech']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1fa994d-8ab6-47be-8074-9d10812cd5a8",
      "metadata": {
        "id": "c1fa994d-8ab6-47be-8074-9d10812cd5a8",
        "outputId": "b46e0dae-c164-499c-f102-34662d425e8d"
      },
      "outputs": [
        {
          "ename": "URLError",
          "evalue": "<urlopen error [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)>",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSSLEOFError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1329\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1455\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1100\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
            "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1371\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[0;31mSSLEOFError\u001b[0m: [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m link2text \n\u001b[1;32m      2\u001b[0m links \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.bbc.com/news/business-67304260\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.bbc.com/news/business-67305453\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.bbc.com/news/world-europe-67321777\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolitics\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m text, labels \u001b[38;5;241m=\u001b[39m \u001b[43mlink2text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     16\u001b[0m preds \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(text)\n",
            "File \u001b[0;32m/workspace/ML/NLP/bbc-news/data.py:51\u001b[0m, in \u001b[0;36mlink2text\u001b[0;34m(links)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlink2text\u001b[39m(links):\n\u001b[0;32m---> 51\u001b[0m     contents \u001b[38;5;241m=\u001b[39m [(url2text(url), links[url] ) \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m links\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m     52\u001b[0m     text \u001b[38;5;241m=\u001b[39m [c[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m contents]\n\u001b[1;32m     53\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [c[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m contents]\n",
            "File \u001b[0;32m/workspace/ML/NLP/bbc-news/data.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlink2text\u001b[39m(links):\n\u001b[0;32m---> 51\u001b[0m     contents \u001b[38;5;241m=\u001b[39m [(\u001b[43murl2text\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m, links[url] ) \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m links\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[1;32m     52\u001b[0m     text \u001b[38;5;241m=\u001b[39m [c[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m contents]\n\u001b[1;32m     53\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [c[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m contents]\n",
            "File \u001b[0;32m/workspace/ML/NLP/bbc-news/data.py:20\u001b[0m, in \u001b[0;36murl2text\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mReference:\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m* https://stackoverflow.com/questions/45768441/hangs-on-open-url-with-urllib-python3\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m req \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m     14\u001b[0m     url, \n\u001b[1;32m     15\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m         }\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# kill all script and style elements\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)>"
          ]
        }
      ],
      "source": [
        "from data import link2text\n",
        "links = {\n",
        "    \"https://www.bbc.com/news/business-67304260\": \"business\",\n",
        "    \"https://www.bbc.com/news/business-67305453\": \"business\",\n",
        "    \"https://www.bbc.com/sport/football/67323707\": \"sport\",\n",
        "    \"https://www.bbc.com/sport/football/67324261\": \"sport\",\n",
        "    \"https://www.bbc.com/news/technology-67302788\": \"tech\",\n",
        "    \"https://www.bbc.com/news/science-environment-67243772\": \"tech\",\n",
        "    \"https://www.bbc.com/news/entertainment-arts-67207695\": \"entertainment\",\n",
        "    \"https://www.bbc.com/news/entertainment-arts-67311637\": \"entertainment\",\n",
        "    \"https://www.bbc.com/news/uk-politics-67320861\": \"politics\",\n",
        "    \"https://www.bbc.com/news/world-europe-67321777\": \"politics\"\n",
        "}\n",
        "text, labels = link2text(links)\n",
        "#\n",
        "preds = predictor.predict(text)\n",
        "print(\"{:>15s} | {:<15s}\".format(\"Label\", \"Prediction\"))\n",
        "print(\"-\"*100)\n",
        "for lb, pred in zip(labels, preds):\n",
        "    print(\"{:>15s} | {:<15s}\".format(lb, pred))\n",
        "print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0f630b-2864-4a9e-9005-62f0a7d9e7c4",
      "metadata": {
        "id": "7e0f630b-2864-4a9e-9005-62f0a7d9e7c4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}